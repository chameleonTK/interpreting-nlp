{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q \"transformers==4.5.1\"\n",
    "# !pip install -q yattag\n",
    "# !pip install -q sentencepiece \n",
    "# !pip install -q datasets\n",
    "# !pip install jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from IPython.core.display import display, HTML\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "from lrp_bert_modules import LRPBertForSequenceClassification\n",
    "from heatmap import html_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"mbert\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7164bef36dd8456d936f53b6a3437dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=995526.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8b907289a804440849055ce954c8d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1961828.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d9f796f18064d679c4da716e9809aae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=29.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "import os\n",
    "\n",
    "from transformers import (\n",
    "    # AutoTokenizer, \n",
    "    AutoModel,\n",
    "    AutoModelForSequenceClassification, \n",
    "    AutoConfig,\n",
    "    CamembertTokenizer,\n",
    "    BertTokenizer,\n",
    "    BertTokenizerFast,\n",
    "    BertConfig,\n",
    "    XLMRobertaTokenizer,\n",
    "    XLMRobertaTokenizerFast,\n",
    "    XLMRobertaConfig,\n",
    ")\n",
    "\n",
    "config = BertConfig.from_pretrained('bert-base-multilingual-cased')\n",
    "config.num_labels = 4\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-multilingual-cased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading model...\")\n",
    "\n",
    "\n",
    "state_dict_path = os.path.join(\"../../results\", 'mbert.pt')\n",
    "state_dict = torch.load(state_dict_path)\n",
    "\n",
    "# pooler layer?? https://github.com/google-research/bert/issues/1102\n",
    "model = LRPBertForSequenceClassification(config)\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "model.eval()\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4201166213e4422dac92727eb14858f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1883.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b243b875e7d4492a93f96b013ea6120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1555.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading and preparing dataset wisesight_sentiment/wisesight_sentiment (download: 2.00 MiB, generated: 6.28 MiB, post-processed: Unknown size, total: 8.28 MiB) to C:\\Users\\Tk\\.cache\\huggingface\\datasets\\wisesight_sentiment\\wisesight_sentiment\\1.0.0\\caa11b92fd29eb91216ff65874c33dffe7d18fff564b073bbf60f2c92693c419...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wisesight_sentiment downloaded and prepared to C:\\Users\\Tk\\.cache\\huggingface\\datasets\\wisesight_sentiment\\wisesight_sentiment\\1.0.0\\caa11b92fd29eb91216ff65874c33dffe7d18fff564b073bbf60f2c92693c419. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, list_metrics, load_dataset, Dataset\n",
    "DATASET_METADATA = {\n",
    "    'wisesight_sentiment': {\n",
    "        'huggingface_dataset_name': 'wisesight_sentiment',\n",
    "        # 'task': Task.MULTICLASS_CLS,\n",
    "        'text_input_col_name': 'texts',\n",
    "        'label_col_name': 'category',\n",
    "        'num_labels': 4,\n",
    "        'split_names': ['train', 'validation', 'test']\n",
    "    }\n",
    "}\n",
    "dataset = load_dataset(DATASET_METADATA[\"wisesight_sentiment\"][\"huggingface_dataset_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "    \n",
    "def calLRP(model, tokenizer, s):\n",
    "    inputs = tokenizer(s, return_tensors=\"pt\")\n",
    "    model.attr()\n",
    "    output = model(**inputs)\n",
    "\n",
    "    o = {}\n",
    "    o[\"text\"] = s\n",
    "\n",
    "    input_ids = inputs.input_ids.detach().cpu().numpy()[0]\n",
    "\n",
    "    rel_y = np.zeros(output.shape)\n",
    "    rel_y[:, 1] = output[:, 1]\n",
    "    rel_word, rel_pos, rel_type, rel_embed = model.attr_backward(rel_y, eps=.1)\n",
    "    # print(rel_word, rel_word.shape)\n",
    "    # rel_word = np.sum(rel_word[0, 1:-1], -1)\n",
    "    # rel_pos = np.sum(rel_pos[0, 1:-1], -1)\n",
    "    # rel_type = np.sum(rel_type[0, 1:-1], -1)\n",
    "    # rel_embed = np.sum(rel_embed[0, 1:-1], -1)\n",
    "\n",
    "    o[\"tokens\"] = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    o[\"output\"] = output.tolist()\n",
    "    o[\"lrp_word\"] = rel_word.tolist()\n",
    "    o[\"lrp_pos\"] = rel_pos.tolist()\n",
    "    o[\"lrp_type\"] = rel_type.tolist()\n",
    "    o[\"lrp_embed\"] = rel_embed.tolist()\n",
    "\n",
    "    return o\n",
    "\n",
    "# test_example = \"ดูซิแมวตัวนั้นน่ารักมากกกกกกก\"\n",
    "# model.eval()\n",
    "# o = calLRP(model, tokenizer, test_example)\n",
    "# output = o[\"output\"]\n",
    "# print(\"Attr Forward Pass Output:\")\n",
    "# print(output)\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import jsonlines\n",
    "import json\n",
    "model.cuda()\n",
    "model.eval()\n",
    "raw_data = []\n",
    "\n",
    "for i, t in tqdm(enumerate(dataset[\"validation\"])):\n",
    "    o = calLRP(model, tokenizer, t[\"texts\"])\n",
    "    raw_data.append(o)\n",
    "\n",
    "    if i%10==0:\n",
    "\n",
    "    with jsonlines.open(f\"../../lrp-mbert-validation{i}.jsonl\", 'w') as writer:\n",
    "        writer.write_all(raw_data)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
